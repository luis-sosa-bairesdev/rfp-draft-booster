# Epic 6: Service Matching Screen - Technical Spike

**Date:** 2025-11-13  
**Epic Key:** RDBP-69 (Proposed)  
**Type:** Discovery / Spike  
**Status:** üìã Planning

---

## üéØ Executive Summary

**Goal:** Add intelligent service-to-requirement matching to help sales teams quickly identify which BairesDev offerings best fulfill each RFP requirement, reducing proposal assembly time by 50%.

**Approach:** Create a new "Service Matching" tab in Streamlit that uses TF-IDF vectorization + cosine similarity to compute match scores between extracted requirements and a catalog of BairesDev services.

**Value Proposition:**
- **Speed:** Automated matching in <1 second vs. 2-4 hours manual analysis
- **Accuracy:** Semantic similarity catches matches humans might miss
- **Insights:** Visual breakdown shows coverage gaps before drafting
- **Integration:** Top matches feed into Draft Generation for tailored proposals

---

## üìä Problem Statement

### Current Pain Point

After extracting requirements (Epic 3), sales teams must manually:
1. Read through each requirement (20-50 items)
2. Search internal service catalog/documentation
3. Determine which offerings match
4. Document the mapping for proposal writing

**Time Cost:** 2-4 hours per RFP  
**Error Rate:** 15-20% of matches missed or incorrectly identified

### Desired State

System automatically suggests service matches with confidence scores, allowing sales to:
- Review and approve matches in 15-30 minutes
- Focus on strategic positioning vs. manual lookup
- Generate drafts with pre-selected services

---

## üèóÔ∏è Architecture & Design

### 1. UI Integration

**Location:** New sidebar tab between "üìã Requirements" and "‚ö†Ô∏è Risk Analysis"

```
Sidebar:
‚îú‚îÄ‚îÄ üì§ Upload RFP
‚îú‚îÄ‚îÄ üìã Requirements
‚îú‚îÄ‚îÄ üîó Service Matching ‚Üê NEW
‚îú‚îÄ‚îÄ ‚ö†Ô∏è Risk Analysis
‚îî‚îÄ‚îÄ ‚úçÔ∏è Draft Generation
```

**Page Structure:**
```
Service Matching
‚îú‚îÄ‚îÄ Header: Stats (X requirements, Y services, Avg Z% match)
‚îú‚îÄ‚îÄ Filters:
‚îÇ   ‚îú‚îÄ‚îÄ Category Dropdown (All, Technical, Functional, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ Match % Slider (Min threshold: 0-100%)
‚îÇ   ‚îî‚îÄ‚îÄ Sort Order (Highest Match First)
‚îú‚îÄ‚îÄ Match Table:
‚îÇ   ‚îú‚îÄ‚îÄ Columns: [Req ID, Description, Matched Service, % Fit, Approve]
‚îÇ   ‚îî‚îÄ‚îÄ Color Coding: Green (>80%), Yellow (50-80%), Red (<50%)
‚îú‚îÄ‚îÄ Match Coverage Chart:
‚îÇ   ‚îú‚îÄ‚îÄ Bar chart by requirement category
‚îÇ   ‚îî‚îÄ‚îÄ Subtitle: Overall avg match %
‚îî‚îÄ‚îÄ Actions:
    ‚îî‚îÄ‚îÄ "Export Matches" button (JSON download)
```

### 2. Data Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Session State   ‚îÇ
‚îÇ - Requirements  ‚îÇ ‚îÄ‚îê
‚îÇ - Services      ‚îÇ  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ TF-IDF       ‚îÇ
              ‚îÇ Vectorizer   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ Cosine       ‚îÇ
              ‚îÇ Similarity   ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ Match Scores ‚îÇ
              ‚îÇ + Ranking    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ UI Display + Filters   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Approved Matches       ‚îÇ
         ‚îÇ ‚Üí Draft Generation     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3. Service Catalog Structure

**File:** `data/services.json`

```json
[
  {
    "id": "svc-microservices-k8s",
    "name": "Microservices Architecture with Kubernetes",
    "category": "technical",
    "description": "End-to-end microservices design, containerization, Kubernetes orchestration, CI/CD pipeline, 99.9% uptime SLA, auto-scaling, monitoring with Prometheus/Grafana",
    "capabilities": [
      "Docker containerization",
      "Kubernetes cluster setup",
      "Service mesh (Istio/Linkerd)",
      "Auto-scaling policies",
      "99.9% uptime guarantee",
      "24/7 monitoring",
      "CI/CD with Jenkins/GitLab"
    ],
    "tags": ["microservices", "kubernetes", "k8s", "containers", "docker", "orchestration", "scalability", "high-availability", "SLA"],
    "pricing_model": "custom",
    "typical_duration": "12-16 weeks",
    "success_rate": 0.95,
    "past_projects": 42
  },
  {
    "id": "svc-cloud-migration-aws",
    "name": "AWS Cloud Migration",
    "category": "technical",
    "description": "Full AWS migration service including assessment, architecture design, data migration, security setup, cost optimization, and post-migration support",
    "capabilities": [
      "AWS infrastructure design",
      "EC2/ECS/EKS setup",
      "RDS/DynamoDB migration",
      "S3 storage strategy",
      "IAM and security policies",
      "Cost optimization",
      "Disaster recovery"
    ],
    "tags": ["aws", "cloud", "migration", "ec2", "s3", "rds", "infrastructure", "terraform", "cloudformation"],
    "pricing_model": "time_material",
    "typical_duration": "8-12 weeks",
    "success_rate": 0.92,
    "past_projects": 38
  },
  {
    "id": "svc-agile-transformation",
    "name": "Agile Transformation Consulting",
    "category": "functional",
    "description": "Agile methodology implementation, Scrum/Kanban training, team coaching, ceremony facilitation, metrics tracking, continuous improvement",
    "capabilities": [
      "Scrum Master coaching",
      "Sprint planning",
      "Daily standups facilitation",
      "Retrospectives",
      "Velocity tracking",
      "Backlog management",
      "Agile metrics dashboard"
    ],
    "tags": ["agile", "scrum", "kanban", "coaching", "training", "methodology", "sprint", "backlog"],
    "pricing_model": "hourly",
    "typical_duration": "6-12 months",
    "success_rate": 0.88,
    "past_projects": 25
  },
  {
    "id": "svc-devops-cicd",
    "name": "DevOps & CI/CD Pipeline",
    "category": "technical",
    "description": "Complete DevOps practice setup including CI/CD pipelines, infrastructure as code, automated testing, deployment automation, monitoring, and alerting",
    "capabilities": [
      "Jenkins/GitLab CI setup",
      "Docker containerization",
      "Terraform/Ansible IaC",
      "Automated testing integration",
      "Blue-green deployments",
      "Monitoring (Prometheus/Grafana)",
      "Log aggregation (ELK)"
    ],
    "tags": ["devops", "cicd", "jenkins", "gitlab", "terraform", "ansible", "automation", "deployment", "monitoring"],
    "pricing_model": "fixed",
    "typical_duration": "10-14 weeks",
    "success_rate": 0.94,
    "past_projects": 51
  },
  {
    "id": "svc-api-development",
    "name": "RESTful API Development",
    "category": "technical",
    "description": "Enterprise-grade REST API development with authentication, rate limiting, versioning, documentation, testing, and monitoring",
    "capabilities": [
      "REST API design",
      "OpenAPI/Swagger docs",
      "OAuth2/JWT auth",
      "Rate limiting",
      "API versioning",
      "Integration testing",
      "Performance optimization"
    ],
    "tags": ["api", "rest", "restful", "backend", "authentication", "oauth", "jwt", "swagger", "openapi"],
    "pricing_model": "time_material",
    "typical_duration": "8-12 weeks",
    "success_rate": 0.91,
    "past_projects": 47
  },
  {
    "id": "svc-data-analytics",
    "name": "Business Intelligence & Analytics",
    "category": "functional",
    "description": "Data warehouse design, ETL pipelines, analytics dashboards, predictive models, reporting automation, data governance",
    "capabilities": [
      "Data warehouse (Snowflake/Redshift)",
      "ETL with Airflow/dbt",
      "Power BI/Tableau dashboards",
      "Python analytics (Pandas/NumPy)",
      "Machine learning models",
      "Automated reporting",
      "Data quality monitoring"
    ],
    "tags": ["analytics", "bi", "business-intelligence", "data", "etl", "dashboard", "reporting", "ml", "machine-learning"],
    "pricing_model": "custom",
    "typical_duration": "12-20 weeks",
    "success_rate": 0.89,
    "past_projects": 33
  },
  {
    "id": "svc-mobile-app-dev",
    "name": "Cross-Platform Mobile App",
    "category": "technical",
    "description": "React Native or Flutter mobile app development for iOS and Android with backend integration, offline support, push notifications",
    "capabilities": [
      "React Native/Flutter",
      "iOS and Android apps",
      "Backend API integration",
      "Offline-first architecture",
      "Push notifications",
      "App store deployment",
      "Performance optimization"
    ],
    "tags": ["mobile", "app", "react-native", "flutter", "ios", "android", "cross-platform", "push-notifications"],
    "pricing_model": "fixed",
    "typical_duration": "16-24 weeks",
    "success_rate": 0.87,
    "past_projects": 29
  },
  {
    "id": "svc-security-audit",
    "name": "Security Audit & Penetration Testing",
    "category": "compliance",
    "description": "Comprehensive security assessment, vulnerability scanning, penetration testing, compliance review, remediation guidance",
    "capabilities": [
      "OWASP Top 10 testing",
      "Network penetration testing",
      "Application security review",
      "Code security analysis",
      "Compliance assessment (SOC 2, ISO 27001)",
      "Remediation roadmap",
      "Security training"
    ],
    "tags": ["security", "audit", "penetration-testing", "pentest", "vulnerability", "compliance", "owasp", "soc2", "iso27001"],
    "pricing_model": "fixed",
    "typical_duration": "4-6 weeks",
    "success_rate": 0.96,
    "past_projects": 18
  },
  {
    "id": "svc-ui-ux-design",
    "name": "UI/UX Design & Prototyping",
    "category": "functional",
    "description": "User research, wireframing, high-fidelity mockups, interactive prototypes, usability testing, design system creation",
    "capabilities": [
      "User research and personas",
      "Wireframing (Figma/Sketch)",
      "High-fidelity mockups",
      "Interactive prototypes",
      "Usability testing",
      "Design system (Storybook)",
      "Accessibility (WCAG 2.1)"
    ],
    "tags": ["design", "ui", "ux", "user-experience", "figma", "prototyping", "wireframes", "accessibility", "wcag"],
    "pricing_model": "hourly",
    "typical_duration": "6-10 weeks",
    "success_rate": 0.93,
    "past_projects": 36
  },
  {
    "id": "svc-tech-support-sla",
    "name": "24/7 Technical Support - Enterprise SLA",
    "category": "technical",
    "description": "Round-the-clock technical support with guaranteed response times, incident management, proactive monitoring, escalation procedures",
    "capabilities": [
      "24/7/365 support",
      "15-minute critical response",
      "2-hour high-priority response",
      "Incident management (Jira/ServiceNow)",
      "Proactive monitoring",
      "Monthly SLA reports",
      "Dedicated account manager"
    ],
    "tags": ["support", "sla", "24/7", "technical-support", "monitoring", "incident", "helpdesk", "maintenance"],
    "pricing_model": "subscription",
    "typical_duration": "12-month contracts",
    "success_rate": 0.98,
    "past_projects": 62
  }
]
```

**Key Design Decisions:**
- **10 diverse services** covering common BairesDev offerings
- **Rich descriptions** for better semantic matching
- **Multiple tags** for keyword-based boosting
- **Real metrics** (success_rate, past_projects) for credibility
- **Category alignment** with requirement categories

### 4. Matching Algorithm

**Technology Stack:**
- `scikit-learn`: TF-IDF vectorization + cosine similarity
- `numpy`: Array operations
- `pandas`: Data manipulation

**Implementation:**

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd

class ServiceMatcher:
    """Match requirements to services using TF-IDF + cosine similarity."""
    
    def __init__(self, services: List[dict]):
        self.services = services
        self.vectorizer = TfidfVectorizer(
            max_features=500,
            stop_words='english',
            ngram_range=(1, 2),  # Unigrams + bigrams
            min_df=1
        )
        self._build_service_vectors()
    
    def _build_service_vectors(self):
        """Pre-compute TF-IDF vectors for all services."""
        service_texts = []
        for svc in self.services:
            # Combine name, description, capabilities, tags
            combined_text = (
                f"{svc['name']} {svc['description']} "
                f"{' '.join(svc['capabilities'])} {' '.join(svc['tags'])}"
            )
            service_texts.append(combined_text)
        
        self.service_vectors = self.vectorizer.fit_transform(service_texts)
    
    def match_requirement(self, requirement: Requirement) -> List[dict]:
        """
        Find top matching services for a requirement.
        
        Returns:
            List of matches sorted by score descending:
            [
                {
                    'requirement_id': str,
                    'requirement_desc': str,
                    'service_id': str,
                    'service_name': str,
                    'match_score': float (0.0-1.0),
                    'match_percentage': int (0-100),
                    'reasoning': str
                },
                ...
            ]
        """
        # Vectorize requirement text
        req_text = f"{requirement.description} {requirement.category}"
        req_vector = self.vectorizer.transform([req_text])
        
        # Compute cosine similarity with all services
        similarities = cosine_similarity(req_vector, self.service_vectors)[0]
        
        # Get top 3 matches
        top_indices = np.argsort(similarities)[::-1][:3]
        
        matches = []
        for idx in top_indices:
            score = float(similarities[idx])
            if score < 0.30:  # Threshold: ignore very low matches
                continue
            
            service = self.services[idx]
            matches.append({
                'requirement_id': requirement.id,
                'requirement_desc': requirement.description[:100] + '...',
                'requirement_category': requirement.category,
                'service_id': service['id'],
                'service_name': service['name'],
                'match_score': score,
                'match_percentage': int(score * 100),
                'reasoning': self._generate_reasoning(requirement, service, score),
                'color': self._get_color_code(score)
            })
        
        return matches
    
    def match_all_requirements(self, requirements: List[Requirement]) -> pd.DataFrame:
        """Match all requirements and return as DataFrame."""
        all_matches = []
        for req in requirements:
            req_matches = self.match_requirement(req)
            if req_matches:
                # Take best match
                all_matches.append(req_matches[0])
        
        return pd.DataFrame(all_matches)
    
    def _generate_reasoning(self, req: Requirement, service: dict, score: float) -> str:
        """Generate human-readable reasoning for match."""
        if score >= 0.80:
            return f"Strong match: Service capabilities directly address requirement. Match: {int(score*100)}%"
        elif score >= 0.60:
            return f"Good match: Service covers key aspects of requirement. Match: {int(score*100)}%"
        elif score >= 0.40:
            return f"Partial match: Service may fulfill requirement with customization. Match: {int(score*100)}%"
        else:
            return f"Weak match: Limited alignment with requirement. Match: {int(score*100)}%"
    
    def _get_color_code(self, score: float) -> str:
        """Return color for UI display."""
        if score >= 0.80:
            return "üü¢"  # Green
        elif score >= 0.50:
            return "üü°"  # Yellow
        else:
            return "üî¥"  # Red
    
    def calculate_coverage_by_category(self, matches_df: pd.DataFrame) -> dict:
        """Calculate average match % by requirement category."""
        if matches_df.empty:
            return {}
        
        coverage = {}
        for category in matches_df['requirement_category'].unique():
            cat_matches = matches_df[matches_df['requirement_category'] == category]
            avg_score = cat_matches['match_percentage'].mean()
            coverage[category] = avg_score
        
        return coverage
```

**Performance:**
- **Vectorization:** O(n) for n services (one-time setup)
- **Matching:** O(m) for m requirements (cosine similarity is fast)
- **Total:** <1 second for 50 requirements √ó 10 services

### 5. UI Implementation

**Page File:** `pages/3_üîó_Service_Matching.py`

```python
import streamlit as st
import pandas as pd
import json
from pathlib import Path

from models import Requirement
from services.service_matcher import ServiceMatcher
from utils.session import get_current_requirements
from components.ai_assistant import render_ai_assistant_button, render_ai_assistant_modal

def load_services() -> list:
    """Load service catalog from JSON."""
    services_path = Path(__file__).parent.parent / "data" / "services.json"
    with open(services_path, 'r') as f:
        return json.load(f)

def main():
    """Service Matching page."""
    
    # Render AI Assistant modal if open
    if st.session_state.get("show_ai_assistant", False):
        render_ai_assistant_modal(key_suffix="service_matching", page_context="service_matching")
        st.markdown("---")
    
    st.title("üîó Service Matching")
    st.markdown("Match RFP requirements to BairesDev service offerings")
    
    # Get requirements from session
    requirements = get_current_requirements()
    
    if not requirements:
        st.warning("‚ö†Ô∏è No requirements found. Please extract requirements first.")
        if st.button("‚Üê Go to Requirements Page"):
            st.switch_page("pages/2_üìã_Requirements.py")
        return
    
    # Load services
    try:
        services = load_services()
    except FileNotFoundError:
        st.error("‚ùå Service catalog not found. Please contact administrator.")
        return
    
    # Initialize matcher
    if 'service_matcher' not in st.session_state:
        st.session_state.service_matcher = ServiceMatcher(services)
    
    matcher = st.session_state.service_matcher
    
    # --- COMPUTE MATCHES ---
    with st.spinner("üîç Computing service matches..."):
        matches_df = matcher.match_all_requirements(requirements)
    
    if matches_df.empty:
        st.warning("No suitable service matches found.")
        return
    
    # --- HEADER STATS ---
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Requirements", len(requirements))
    with col2:
        st.metric("Available Services", len(services))
    with col3:
        avg_match = matches_df['match_percentage'].mean()
        st.metric("Avg Match %", f"{avg_match:.0f}%")
    
    st.markdown("---")
    
    # --- FILTERS ---
    st.subheader("üîç Filters")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        categories = ["All"] + sorted(matches_df['requirement_category'].unique().tolist())
        selected_category = st.selectbox("Requirement Category", categories, key="filter_category")
    
    with col2:
        min_match_pct = st.slider(
            "Minimum Match %",
            min_value=0,
            max_value=100,
            value=50,
            step=10,
            key="filter_min_match"
        )
    
    with col3:
        sort_order = st.selectbox(
            "Sort By",
            ["Highest Match First", "Lowest Match First", "Requirement ID"],
            key="filter_sort"
        )
    
    # Apply filters
    filtered_df = matches_df.copy()
    
    if selected_category != "All":
        filtered_df = filtered_df[filtered_df['requirement_category'] == selected_category]
    
    filtered_df = filtered_df[filtered_df['match_percentage'] >= min_match_pct]
    
    if sort_order == "Highest Match First":
        filtered_df = filtered_df.sort_values('match_percentage', ascending=False)
    elif sort_order == "Lowest Match First":
        filtered_df = filtered_df.sort_values('match_percentage', ascending=True)
    else:
        filtered_df = filtered_df.sort_values('requirement_id')
    
    st.markdown("---")
    
    # --- MATCH TABLE ---
    st.subheader("üìä Service Matches")
    st.markdown(f"Showing **{len(filtered_df)}** matches")
    
    if filtered_df.empty:
        st.info("No matches found with current filters. Try adjusting the minimum match %.")
    else:
        # Add approval checkboxes
        if 'approved_matches' not in st.session_state:
            st.session_state.approved_matches = set()
        
        # Display table with custom formatting
        display_df = filtered_df.copy()
        display_df['Match'] = display_df.apply(
            lambda row: f"{row['color']} {row['match_percentage']}%", axis=1
        )
        
        # Show dataframe
        st.dataframe(
            display_df[[
                'requirement_id',
                'requirement_desc',
                'service_name',
                'Match',
                'reasoning'
            ]].rename(columns={
                'requirement_id': 'Req ID',
                'requirement_desc': 'Requirement',
                'service_name': 'Matched Service',
                'Match': '% Fit',
                'reasoning': 'Reasoning'
            }),
            use_container_width=True,
            hide_index=True
        )
        
        # Approval section
        st.markdown("---")
        st.subheader("‚úÖ Approve Matches")
        st.markdown("Select matches to use in draft generation:")
        
        approved_count = 0
        for idx, row in filtered_df.iterrows():
            match_key = f"{row['requirement_id']}_{row['service_id']}"
            is_approved = st.checkbox(
                f"{row['color']} **{row['service_name']}** for _{row['requirement_desc'][:60]}..._ ({row['match_percentage']}%)",
                value=match_key in st.session_state.approved_matches,
                key=f"approve_{match_key}"
            )
            
            if is_approved:
                st.session_state.approved_matches.add(match_key)
                approved_count += 1
            elif match_key in st.session_state.approved_matches:
                st.session_state.approved_matches.remove(match_key)
        
        st.info(f"‚ÑπÔ∏è {approved_count} matches approved. These will be used in draft generation.")
    
    st.markdown("---")
    
    # --- COVERAGE CHART ---
    st.subheader("üìà Match Coverage by Category")
    coverage = matcher.calculate_coverage_by_category(matches_df)
    
    if coverage:
        coverage_df = pd.DataFrame(
            list(coverage.items()),
            columns=['Category', 'Avg Match %']
        )
        st.bar_chart(coverage_df.set_index('Category'))
        st.caption(f"Overall Average: **{avg_match:.1f}%**")
    
    # --- EXPORT ---
    st.markdown("---")
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("üíæ Export Matches", key="export_matches"):
            matches_json = filtered_df.to_dict(orient='records')
            st.download_button(
                "‚¨áÔ∏è Download JSON",
                data=json.dumps(matches_json, indent=2),
                file_name=f"service_matches_{st.session_state.rfp.id if st.session_state.rfp else 'unknown'}.json",
                mime="application/json"
            )

if __name__ == "__main__":
    main()
```

---

## üìã Implementation Plan

### Phase 1: Data Setup (2 hours)

**Tasks:**
1. ‚úÖ Create `data/services.json` with 10 BairesDev offerings
2. ‚úÖ Define service schema (id, name, category, description, capabilities, tags, metrics)
3. ‚úÖ Validate JSON structure and completeness

**Deliverables:**
- `data/services.json` (complete service catalog)

### Phase 2: Matching Service (4 hours)

**Tasks:**
1. Create `src/services/service_matcher.py`
2. Implement `ServiceMatcher` class with TF-IDF vectorization
3. Add `match_requirement()` method (cosine similarity)
4. Add `match_all_requirements()` method (batch processing)
5. Add `calculate_coverage_by_category()` for charts
6. Add reasoning generation logic
7. Add color coding logic

**Dependencies:**
- `scikit-learn` (already in requirements)
- `numpy` (already in requirements)
- `pandas` (already in requirements)

**Deliverables:**
- `src/services/service_matcher.py` (matching engine)

### Phase 3: UI Page (4 hours)

**Tasks:**
1. Create `pages/3_üîó_Service_Matching.py`
2. Update sidebar page numbering (shift Risk Analysis to 4, Draft to 5)
3. Implement header with stats (requirements, services, avg match)
4. Add filters (category dropdown, match % slider, sort order)
5. Display matches table with color coding
6. Add approval checkboxes for each match
7. Create coverage bar chart
8. Add export functionality

**Deliverables:**
- `pages/3_üîó_Service_Matching.py` (complete UI)

### Phase 4: Integration (3 hours)

**Tasks:**
1. Update `src/utils/session.py` to store approved matches
2. Modify Draft Generation prompt template to include top matches
3. Update Draft Generation page to use approved matches
4. Add AI Assistant page-specific help for Service Matching
5. Test end-to-end flow: Upload ‚Üí Requirements ‚Üí Matching ‚Üí Draft

**Deliverables:**
- Updated `src/utils/prompt_templates.py`
- Updated `pages/5_‚úçÔ∏è_Draft_Generation.py` (renumbered)
- Updated `src/utils/session.py`

### Phase 5: Testing (3 hours)

**Tasks:**
1. Create unit tests for `ServiceMatcher`:
   - `test_match_requirement()` (single req)
   - `test_match_all_requirements()` (batch)
   - `test_calculate_coverage()` (chart data)
   - `test_color_coding()` (green/yellow/red)
2. Create UI tests for Service Matching page:
   - Filter logic (category, match %, sort)
   - Approval checkbox state management
   - Export functionality
3. Manual testing with sample RFPs

**Deliverables:**
- `tests/test_services/test_service_matcher.py`
- `tests/test_ui/test_service_matching_page.py`
- Test coverage >80%

### Phase 6: Documentation (2 hours)

**Tasks:**
1. Update PRD with FR-006 details
2. Create service catalog maintenance guide
3. Add "Service Matching" to user documentation
4. Update architecture diagrams

**Deliverables:**
- Updated `deliverables/prd-rfp-draft-booster.md`
- `deliverables/SERVICE-CATALOG-GUIDE.md`

**Total Estimated Effort:** 18 hours (~2.5 days)

---

## ‚ö†Ô∏è Risks & Mitigations

### Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Low match scores** (all <50%) | High - No useful matches | Medium | Expand service descriptions, add more tags, tune TF-IDF parameters |
| **Performance with large catalogs** (100+ services) | Medium - Slow matching | Low | Pre-compute vectors, cache results, paginate UI |
| **Ambiguous requirements** (short, unclear text) | Medium - Poor matches | Medium | Prompt user to clarify, add manual override |
| **Service catalog outdated** | Low - Wrong suggestions | Medium | Add admin page for catalog management (future) |

### UX Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Overwhelming UI** (too many matches) | Medium - Confusing | Low | Default filters (>50% only), top 1 match per req |
| **Approval friction** (tedious checkboxes) | Low - Slow workflow | Low | Auto-approve >80% matches, bulk actions |
| **Chart not insightful** | Low - Ignored feature | Low | Add tooltips, interactive drilldowns |

### Integration Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Draft Generation ignores matches** | High - No value | Low | Explicit prompt engineering, QA testing |
| **Session state conflicts** | Medium - Lost data | Low | Test state persistence, add data validation |

---

## üéØ Success Criteria

### Functional Requirements

- ‚úÖ **FR-6.1:** System displays new "Service Matching" tab between Requirements and Risk Analysis
- ‚úÖ **FR-6.2:** System matches each requirement to at least 1 service (if match >30%)
- ‚úÖ **FR-6.3:** Match computation completes in <2 seconds for 50 requirements
- ‚úÖ **FR-6.4:** Matches are color-coded: Green (>80%), Yellow (50-80%), Red (<50%)
- ‚úÖ **FR-6.5:** Users can filter by category, match %, and sort order
- ‚úÖ **FR-6.6:** Users can approve/reject matches via checkboxes
- ‚úÖ **FR-6.7:** Bar chart shows avg match % by requirement category
- ‚úÖ **FR-6.8:** Users can export matches as JSON
- ‚úÖ **FR-6.9:** Approved matches (>80%) appear in Draft Generation context

### Performance Requirements

- ‚ö° **Matching Speed:** <2 seconds for 50 reqs √ó 10 services
- üìä **UI Responsiveness:** Filters apply in <500ms
- üíæ **Memory:** <100MB for vectorization + matching

### Quality Requirements

- üß™ **Test Coverage:** >80% for matcher service
- üìù **Documentation:** Complete service catalog schema + maintenance guide
- üîç **Accuracy:** Manual validation: 90%+ match relevance

---

## üöÄ Future Enhancements (Post-MVP)

### Stretch Goals

1. **Semantic Embeddings (Gemini/LangChain)**
   - Replace TF-IDF with text-embedding-004
   - Better context understanding (e.g., "high availability" = "99.9% uptime")
   - Cost: ~$0.01 per 1000 requirements (acceptable for scale)

2. **Match Explanation with LLM**
   - Generate detailed reasoning with Gemini
   - Example: "This service matches because it offers Kubernetes orchestration (requirement mentions microservices), auto-scaling (SLA requirement), and has 95% success rate"

3. **Service Catalog Admin UI**
   - Add/edit/delete services via Streamlit page
   - Upload service JSON files
   - Version control for catalog

4. **Confidence Tuning**
   - Allow users to adjust match thresholds per category
   - Learn from approved/rejected matches (feedback loop)

5. **Multi-Service Recommendations**
   - Show top 3 matches per requirement
   - Suggest service bundles (e.g., "Cloud Migration + DevOps")

6. **Historical Data**
   - Track which matches led to won deals
   - Boost services with high win rates

---

## üìö References

### Technical Documentation

- [scikit-learn TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [Cosine Similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)
- [Streamlit Dataframes](https://docs.streamlit.io/library/api-reference/data/st.dataframe)
- [Streamlit Charts](https://docs.streamlit.io/library/api-reference/charts/st.bar_chart)

### Domain Documentation

- `domain/service-catalog-entity.md` - Service data model
- `domain/requirement-entity.md` - Requirement data model
- `.cursor/rules/domain-guidelines.mdc` - Business rules

### Related Epics

- **Epic 3:** Requirement Extraction (provides input data)
- **Epic 5:** Draft Generation (consumes matched services)
- **Epic 7 (Future):** Google Docs Export (export matches)

---

## ‚úÖ Acceptance Checklist

Before marking Epic 6 complete:

- [ ] `data/services.json` created with 10+ BairesDev services
- [ ] `ServiceMatcher` class implemented and tested
- [ ] Service Matching page functional with all filters
- [ ] Color coding working (green/yellow/red)
- [ ] Bar chart displays coverage by category
- [ ] Approval checkboxes persist in session state
- [ ] Top matches (>80%) integrated into Draft Generation
- [ ] Export functionality downloads valid JSON
- [ ] Unit tests pass with >80% coverage
- [ ] UI tests validate filters and state management
- [ ] Manual testing with 3+ sample RFPs
- [ ] Documentation updated (PRD, service catalog guide)
- [ ] Code reviewed and merged

---

## üìû Questions & Clarifications

**Resolved:**
1. ‚úÖ Service catalog location ‚Üí `data/services.json`
2. ‚úÖ Matching algorithm ‚Üí TF-IDF + cosine similarity (no LLM for MVP)
3. ‚úÖ Persistence ‚Üí Session state (no JSON files for now)
4. ‚úÖ Filters ‚Üí Category, match %, sort order
5. ‚úÖ Chart ‚Üí Coverage by category + overall avg
6. ‚úÖ Draft integration ‚Üí Pass top matches >80% as context
7. ‚úÖ Approval ‚Üí Simple checkboxes (no full workflow)

**Open:**
- None

---

**Status:** ‚úÖ Ready for Sprint Planning  
**Next Steps:** 
1. Review spike with team
2. Create Jira Epic 6 + user stories
3. Assign to Sprint 5
4. Begin implementation

---

**Author:** AI Assistant  
**Reviewed By:** TBD  
**Approved By:** TBD

